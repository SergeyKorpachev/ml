{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as k\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.utils import Sequence, plot_model\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.18/04\n"
     ]
    }
   ],
   "source": [
    "from root_pandas import read_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fDataNameTrain = \"./tmva/gun_k0L_allgev_FTFP_BERT_160000evt_ILD_l5_v02steel.root\"\n",
    "fTreeNameTrain = \"tree\"\n",
    "\n",
    "#variables = ([\"energy\", \"eecal\", \"ehcal\", \"nhits\", \"nhits_ecal\", \"nhits_hcal\"])\n",
    "variables1 = ([\"n30\", \"n35\", \"n40\", \"n45\", \"n50\", \"n55\", \"n60\", \"n65\", \"n70\", \"n75\", \"n80\", \"nav\", \"c30\", \"c35\", \"c40\", \"c45\", \"c50\", \"c55\", \"c60\", \"c65\", \"c70\", \"c75\", \"c80\", ])\n",
    "variables2 = ([\"muon_energy\", \"muon_energy_hit\", \"muon_nhits\", \"muon_nhits_t\", \"muon_time\", \"muon_layer\"])\n",
    "target = \"mc_energy\"\n",
    "\n",
    "variables = variables1 + variables2\n",
    "\n",
    "def prepare_data(fName, treeName):\n",
    "#    data = read_root(fName, treeName, columns=variablesLoad)\n",
    "    data = read_root(fName, treeName)\n",
    "\n",
    "    y = data[ target ].values\n",
    "    \n",
    "    for var in variables:\n",
    "        data.drop(var, axis=1, inplace=True)\n",
    "    X = data.values\n",
    "\n",
    "    input_shape = X.shape[1:]\n",
    "\n",
    "    #for i in range(input_shape[0]):\n",
    "    #    X[:,i] = (X[:,i] - np.mean(X[:,i]))/np.std(X[:,i])\n",
    "    return data, X, y, input_shape\n",
    "\n",
    "trainData, X_train, y_train, input_shape = prepare_data( fDataNameTrain, fTreeNameTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "#rs = np.random.RandomState(0)\n",
    "#df = pd.DataFrame(trainData)\n",
    "#corr = df.corr()\n",
    "#corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_true, y_pred):\n",
    "    return k.mean( k.square( (y_pred - y_true)/(y_true)  ) )  !!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-29 01:32:35.855284: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cvmfs/grid.cern.ch/centos7-wn-4.0.5-1_umd4v1/lib64:/cvmfs/grid.cern.ch/centos7-wn-4.0.5-1_umd4v1/lib:/cvmfs/grid.cern.ch/centos7-wn-4.0.5-1_umd4v1/usr/lib64:/cvmfs/grid.cern.ch/centos7-wn-4.0.5-1_umd4v1/usr/lib:/cvmfs/grid.cern.ch/centos7-wn-4.0.5-1_umd4v1/usr/lib64/dcap\n",
      "2020-02-29 01:32:35.855345: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-02-29 01:32:35.855380: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (batch1051.desy.de): /proc/driver/nvidia/version does not exist\n",
      "2020-02-29 01:32:35.856385: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-02-29 01:32:35.881629: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299760000 Hz\n",
      "2020-02-29 01:32:35.887527: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x80887d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-02-29 01:32:35.887603: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "a = Input(shape=input_shape)\n",
    "b = Dense(30)(a)\n",
    "b = Dropout(rate=0.5)(b)\n",
    "b = Activation('sigmoid')(b)\n",
    "b = Dense(20)(a)\n",
    "b = Dropout(rate=0.5)(b)\n",
    "b = Activation('sigmoid')(b)\n",
    "c = Dense(1)(b)\n",
    "\n",
    "model = Model(inputs = a, outputs = c)\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(0.0099)\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.compile(loss=loss, optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testData, X_test, y_val3, input_shape3 = prepare_data(fDataNameTest, fTreeNameTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stopper(Callback):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.s_min = 1\n",
    "        self.n = 0\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        y_pred = self.model.predict_on_batch(self.validation_data[0])[:,0]\n",
    "        self.s = stats.ks_2samp(y_pred, self.validation_data[1][:,0]).statistic\n",
    "        print(self.s)\n",
    "        if self.s < self.s_min:\n",
    "            self.s_min = self.s\n",
    "            self.model.save('ANN.h5')\n",
    "        if logs[\"val_loss\"] > logs[\"loss\"]:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 97621 samples, validate on 41838 samples\n",
      "Epoch 1/100\n",
      "97621/97621 - 2s - loss: 0.0492 - val_loss: 2.0202e-04\n",
      "Epoch 2/100\n",
      "97621/97621 - 2s - loss: 0.0200 - val_loss: 2.0339e-04\n",
      "Epoch 3/100\n",
      "97621/97621 - 2s - loss: 0.0167 - val_loss: 2.0575e-04\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "97621/97621 - 2s - loss: 0.0147 - val_loss: 2.0734e-04\n",
      "Epoch 5/100\n",
      "97621/97621 - 2s - loss: 0.0142 - val_loss: 2.0740e-04\n",
      "Epoch 6/100\n",
      "97621/97621 - 2s - loss: 0.0142 - val_loss: 2.0769e-04\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "97621/97621 - 2s - loss: 0.0141 - val_loss: 2.0791e-04\n",
      "Epoch 8/100\n",
      "97621/97621 - 2s - loss: 0.0140 - val_loss: 2.0802e-04\n",
      "Epoch 9/100\n",
      "97621/97621 - 2s - loss: 0.0138 - val_loss: 2.0818e-04\n",
      "Epoch 10/100\n",
      "97621/97621 - 2s - loss: 0.0138 - val_loss: 2.0838e-04\n",
      "Epoch 11/100\n",
      "97621/97621 - 2s - loss: 0.0138 - val_loss: 2.0837e-04\n",
      "Epoch 12/100\n",
      "97621/97621 - 2s - loss: 0.0137 - val_loss: 2.0860e-04\n",
      "Epoch 13/100\n",
      "97621/97621 - 2s - loss: 0.0136 - val_loss: 2.0854e-04\n",
      "Epoch 14/100\n",
      "97621/97621 - 2s - loss: 0.0136 - val_loss: 2.0867e-04\n",
      "Epoch 15/100\n",
      "97621/97621 - 2s - loss: 0.0136 - val_loss: 2.0863e-04\n",
      "Epoch 16/100\n",
      "97621/97621 - 2s - loss: 0.0135 - val_loss: 2.0874e-04\n",
      "Epoch 17/100\n",
      "97621/97621 - 2s - loss: 0.0135 - val_loss: 2.0871e-04\n",
      "Epoch 18/100\n",
      "97621/97621 - 2s - loss: 0.0134 - val_loss: 2.0870e-04\n",
      "Epoch 19/100\n",
      "97621/97621 - 2s - loss: 0.0134 - val_loss: 2.0881e-04\n",
      "Epoch 20/100\n",
      "97621/97621 - 2s - loss: 0.0134 - val_loss: 2.0865e-04\n",
      "Epoch 21/100\n",
      "97621/97621 - 2s - loss: 0.0133 - val_loss: 2.0872e-04\n",
      "Epoch 22/100\n",
      "97621/97621 - 2s - loss: 0.0133 - val_loss: 2.0876e-04\n",
      "Epoch 23/100\n",
      "97621/97621 - 2s - loss: 0.0132 - val_loss: 2.0864e-04\n",
      "Epoch 24/100\n",
      "97621/97621 - 2s - loss: 0.0132 - val_loss: 2.0857e-04\n",
      "Epoch 25/100\n",
      "97621/97621 - 2s - loss: 0.0132 - val_loss: 2.0862e-04\n",
      "Epoch 26/100\n",
      "97621/97621 - 2s - loss: 0.0131 - val_loss: 2.0862e-04\n",
      "Epoch 27/100\n",
      "97621/97621 - 2s - loss: 0.0131 - val_loss: 2.0863e-04\n",
      "Epoch 28/100\n",
      "97621/97621 - 2s - loss: 0.0131 - val_loss: 2.0865e-04\n",
      "Epoch 29/100\n",
      "97621/97621 - 2s - loss: 0.0130 - val_loss: 2.0855e-04\n",
      "Epoch 30/100\n",
      "97621/97621 - 2s - loss: 0.0130 - val_loss: 2.0851e-04\n",
      "Epoch 31/100\n",
      "97621/97621 - 2s - loss: 0.0130 - val_loss: 2.0860e-04\n",
      "Epoch 32/100\n",
      "97621/97621 - 2s - loss: 0.0130 - val_loss: 2.0848e-04\n",
      "Epoch 33/100\n",
      "97621/97621 - 2s - loss: 0.0129 - val_loss: 2.0843e-04\n",
      "Epoch 34/100\n",
      "97621/97621 - 2s - loss: 0.0129 - val_loss: 2.0837e-04\n",
      "Epoch 35/100\n",
      "97621/97621 - 2s - loss: 0.0129 - val_loss: 2.0835e-04\n",
      "Epoch 36/100\n",
      "97621/97621 - 2s - loss: 0.0128 - val_loss: 2.0842e-04\n",
      "Epoch 37/100\n",
      "97621/97621 - 2s - loss: 0.0128 - val_loss: 2.0836e-04\n",
      "Epoch 38/100\n",
      "97621/97621 - 2s - loss: 0.0128 - val_loss: 2.0827e-04\n",
      "Epoch 39/100\n",
      "97621/97621 - 2s - loss: 0.0127 - val_loss: 2.0810e-04\n",
      "Epoch 40/100\n",
      "97621/97621 - 2s - loss: 0.0127 - val_loss: 2.0809e-04\n",
      "Epoch 41/100\n",
      "97621/97621 - 2s - loss: 0.0127 - val_loss: 2.0819e-04\n",
      "Epoch 42/100\n",
      "97621/97621 - 2s - loss: 0.0127 - val_loss: 2.0806e-04\n",
      "Epoch 43/100\n",
      "97621/97621 - 2s - loss: 0.0126 - val_loss: 2.0810e-04\n",
      "Epoch 44/100\n",
      "97621/97621 - 2s - loss: 0.0126 - val_loss: 2.0802e-04\n",
      "Epoch 45/100\n",
      "97621/97621 - 2s - loss: 0.0126 - val_loss: 2.0803e-04\n",
      "Epoch 46/100\n",
      "97621/97621 - 2s - loss: 0.0125 - val_loss: 2.0807e-04\n",
      "Epoch 47/100\n",
      "97621/97621 - 2s - loss: 0.0125 - val_loss: 2.0809e-04\n",
      "Epoch 48/100\n",
      "97621/97621 - 2s - loss: 0.0125 - val_loss: 2.0801e-04\n",
      "Epoch 49/100\n",
      "97621/97621 - 2s - loss: 0.0125 - val_loss: 2.0805e-04\n",
      "Epoch 50/100\n",
      "97621/97621 - 2s - loss: 0.0124 - val_loss: 2.0796e-04\n",
      "Epoch 51/100\n",
      "97621/97621 - 2s - loss: 0.0124 - val_loss: 2.0794e-04\n",
      "Epoch 52/100\n",
      "97621/97621 - 2s - loss: 0.0124 - val_loss: 2.0802e-04\n",
      "Epoch 53/100\n",
      "97621/97621 - 2s - loss: 0.0124 - val_loss: 2.0793e-04\n",
      "Epoch 54/100\n",
      "97621/97621 - 2s - loss: 0.0124 - val_loss: 2.0795e-04\n",
      "Epoch 55/100\n",
      "97621/97621 - 2s - loss: 0.0123 - val_loss: 2.0789e-04\n",
      "Epoch 56/100\n",
      "97621/97621 - 2s - loss: 0.0123 - val_loss: 2.0799e-04\n",
      "Epoch 57/100\n",
      "97621/97621 - 2s - loss: 0.0123 - val_loss: 2.0785e-04\n",
      "Epoch 58/100\n",
      "97621/97621 - 2s - loss: 0.0123 - val_loss: 2.0785e-04\n",
      "Epoch 59/100\n",
      "97621/97621 - 2s - loss: 0.0122 - val_loss: 2.0789e-04\n",
      "Epoch 60/100\n",
      "97621/97621 - 2s - loss: 0.0123 - val_loss: 2.0797e-04\n",
      "Epoch 61/100\n",
      "97621/97621 - 2s - loss: 0.0122 - val_loss: 2.0789e-04\n",
      "Epoch 62/100\n",
      "97621/97621 - 2s - loss: 0.0122 - val_loss: 2.0793e-04\n",
      "Epoch 63/100\n",
      "97621/97621 - 2s - loss: 0.0122 - val_loss: 2.0800e-04\n",
      "Epoch 64/100\n",
      "97621/97621 - 2s - loss: 0.0121 - val_loss: 2.0790e-04\n",
      "Epoch 65/100\n",
      "97621/97621 - 2s - loss: 0.0121 - val_loss: 2.0789e-04\n",
      "Epoch 66/100\n",
      "97621/97621 - 2s - loss: 0.0121 - val_loss: 2.0794e-04\n",
      "Epoch 67/100\n",
      "97621/97621 - 2s - loss: 0.0121 - val_loss: 2.0801e-04\n",
      "Epoch 68/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0799e-04\n",
      "Epoch 69/100\n",
      "97621/97621 - 2s - loss: 0.0121 - val_loss: 2.0791e-04\n",
      "Epoch 70/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0791e-04\n",
      "Epoch 71/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0791e-04\n",
      "Epoch 72/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0786e-04\n",
      "Epoch 73/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0780e-04\n",
      "Epoch 74/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0774e-04\n",
      "Epoch 75/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0768e-04\n",
      "Epoch 76/100\n",
      "97621/97621 - 2s - loss: 0.0120 - val_loss: 2.0773e-04\n",
      "Epoch 77/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0772e-04\n",
      "Epoch 78/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0772e-04\n",
      "Epoch 79/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0767e-04\n",
      "Epoch 80/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0751e-04\n",
      "Epoch 81/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0752e-04\n",
      "Epoch 82/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0747e-04\n",
      "Epoch 83/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0745e-04\n",
      "Epoch 84/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0748e-04\n",
      "Epoch 85/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0743e-04\n",
      "Epoch 86/100\n",
      "97621/97621 - 2s - loss: 0.0119 - val_loss: 2.0744e-04\n",
      "Epoch 87/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0737e-04\n",
      "Epoch 88/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0744e-04\n",
      "Epoch 89/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0728e-04\n",
      "Epoch 90/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0731e-04\n",
      "Epoch 91/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0726e-04\n",
      "Epoch 92/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0729e-04\n",
      "Epoch 93/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0706e-04\n",
      "Epoch 94/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0723e-04\n",
      "Epoch 95/100\n",
      "97621/97621 - 2s - loss: 0.0117 - val_loss: 2.0712e-04\n",
      "Epoch 96/100\n",
      "97621/97621 - 2s - loss: 0.0117 - val_loss: 2.0711e-04\n",
      "Epoch 97/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0709e-04\n",
      "Epoch 98/100\n",
      "97621/97621 - 2s - loss: 0.0118 - val_loss: 2.0707e-04\n",
      "Epoch 99/100\n",
      "97621/97621 - 2s - loss: 0.0117 - val_loss: 2.0704e-04\n",
      "Epoch 100/100\n",
      "97621/97621 - 2s - loss: 0.0117 - val_loss: 2.0700e-04\n"
     ]
    }
   ],
   "source": [
    "stop = Stopper()\n",
    "# checkpoint = ModelCheckpoint('ANNCorr.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=0.0001, verbose=1)\n",
    "# tb = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "history_train = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.3, verbose=2, callbacks=[reduce_lr])\n",
    "#history_test = model.fit(X_test, y_val3, epochs=100, batch_size=128, validation_split=0.3, verbose=2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ANN.h5')\n",
    "model = load_model('ANN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kss(y_true, y_pred):\n",
    "    y1 = K.cast(tf.sort(y_true), dtype='float32')\n",
    "    y2 = K.cast(tf.sort(y_pred), dtype='float32')\n",
    "    n1 = K.cast(K.shape(y1), dtype='float32')\n",
    "    n2 = K.cast(K.shape(y2), dtype='float32')\n",
    "    y_all = K.concatenate([y1, y2])\n",
    "    cdf1 = K.cast(tf.searchsorted(y1, y_all, side='right'), dtype='float32') / n1\n",
    "    cdf2 = K.cast(tf.searchsorted(y2, y_all, side='right'), dtype='float32') / n2\n",
    "    return K.max(K.abs(cdf1 - cdf2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Input(shape=input_shape)\n",
    "# b = Dense(5, kernel_regularizer=regularizers.l2(0.01))(a)\n",
    "# b = Activation('relu')(b)\n",
    "# b = Dropout(rate=0.8)(b)\n",
    "# b = Dense(10, kernel_regularizer=regularizers.l2(0.01))(b)\n",
    "# b = Activation('relu')(b)\n",
    "# b = Dropout(rate=0.8)(b)\n",
    "# b = Dense(20, kernel_regularizer=regularizers.l2(0.01))(b)\n",
    "# b = Activation('relu')(b)\n",
    "# b = Dropout(rate=0.8)(b)\n",
    "# b = Dense(10, kernel_regularizer=regularizers.l2(0.01))(b)\n",
    "# b = Activation('relu')(b)\n",
    "# b = Dropout(rate=0.8)(b)\n",
    "# b = Dense(5, kernel_regularizer=regularizers.l2(0.01))(b)\n",
    "# b = Activation('relu')(b)\n",
    "# c = Dense(1)(a)\n",
    "\n",
    "# model = Model(inputs = a, outputs = c)\n",
    "\n",
    "# model.compile(loss=loss, optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import pydot\n",
    "#from pydototprint import\n",
    "#plot_model(model, to_file='model.png', show_shapes=True)\n",
    "#Image('model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss', 'lr'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_train.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1e3deda48a4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history_test' is not defined"
     ]
    }
   ],
   "source": [
    "history_test.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history_train.history['loss'])\n",
    "plt.plot(history_train.history['val_loss'])\n",
    "plt.plot(history_train.history['lr'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['loss', 'val_loss', 'lr'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have shape (64,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d3685a549852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;36m45\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, standardize_function, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstandardize_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m       x, y, sample_weights = standardize_function(\n\u001b[0;32m--> 657\u001b[0;31m           x=x, y=y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     self._internal_adapter = TensorLikeDataAdapter(\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    583\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_1 to have shape (64,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.predict( [ 45 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = read_root(\"./data/gun_k0L_5gev_FTFP_BERT_5000evt_ILD_l5_v02steel.root\", \"tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_test = ([\"n30\", \"n35\", \"n40\", \"n45\", \"n50\", \"n55\", \"n60\", \"n65\", \"n70\", \"n75\", \"n80\", \"nav\", \"c30\", \"c35\", \"c40\", \"c45\", \"c50\", \"c55\", \"c60\", \"c65\", \"c70\", \"c75\", \"c80\", ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = [\"energy\", \"eecal\", \"ehcal\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = test[ aaa ].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4451466],\n",
       "       [1.3157029],\n",
       "       [1.7614647],\n",
       "       ...,\n",
       "       [2.0988173],\n",
       "       [2.0988173],\n",
       "       [2.0988173]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict( X_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
